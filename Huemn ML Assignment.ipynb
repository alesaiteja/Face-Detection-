{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1c76831-41d0-4c29-a72f-7bb018df81ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "364bcbfa-84c4-4da8-8595-d01c020b24d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define label-to-name mapping\n",
    "label_to_name = {\n",
    "    1: \"Aaron_Eckhart\",  # Update with actual names\n",
    "    2: \"Aaron_Guiel\",\n",
    "    3: \"Aaron_Patterson\",\n",
    "    4: \"Aaron_Peirsol\",\n",
    "    5: \"Aaron_Pena\",\n",
    "    6: \"Aaron_Sorkin\",\n",
    "    7: \"Aaron_Tippin\",\n",
    "    8: \"Abbas_Kiarostami\",\n",
    "    9: \"Abba_Eban\", \n",
    "    10: \"Abdel_Aziz_Al-Hakim\",\n",
    "    18: \"Abdullah_Gul\",\n",
    "    # Add more mappings as needed\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13cd369c-f384-496f-90dd-912c032f3699",
   "metadata": {},
   "source": [
    "Face Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b32ef796-f823-4ca6-b0cb-7936495f7e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper \n",
    "# Function to detect faces in an image\n",
    "def detect_faces(image_path):\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    img = cv2.imread(image_path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "    return img, gray, faces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433d7413-8e50-4c56-8310-7ac08b90b44b",
   "metadata": {},
   "source": [
    "Prepare Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c51651ae-df3a-4b5b-b93d-16355d365cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to prepare training data\n",
    "def prepare_training_data(data_folder_path, image_size=(100, 100)):\n",
    "    dirs = os.listdir(data_folder_path)\n",
    "    faces = []\n",
    "    labels = []\n",
    "    label_map = {}\n",
    "    next_label = 1\n",
    "\n",
    "    for dir_name in dirs:\n",
    "        # Check if the directory name is an integer\n",
    "        try:\n",
    "            label = int(dir_name)\n",
    "        except ValueError:\n",
    "            # If not, create a mapping for non-integer labels\n",
    "            if dir_name not in label_map:\n",
    "                label_map[dir_name] = next_label\n",
    "                next_label += 1\n",
    "            label = label_map[dir_name]\n",
    "\n",
    "        subject_dir_path = os.path.join(data_folder_path, dir_name)\n",
    "        subject_images_names = os.listdir(subject_dir_path)\n",
    "\n",
    "        for image_name in subject_images_names:\n",
    "            image_path = os.path.join(subject_dir_path, image_name)\n",
    "            img, gray, detected_faces = detect_faces(image_path)\n",
    "            if len(detected_faces) == 0:\n",
    "                continue\n",
    "            (x, y, w, h) = detected_faces[0]\n",
    "            face_img = gray[y:y+h, x:x+w]\n",
    "            \n",
    "            # Resize face images to a consistent size\n",
    "            face_img = cv2.resize(face_img, image_size)\n",
    "            faces.append(face_img)\n",
    "            labels.append(label)\n",
    "\n",
    "    # Convert lists to NumPy arrays\n",
    "    faces = np.array(faces)\n",
    "    labels = np.array(labels, dtype=np.int32)\n",
    "    \n",
    "    return faces, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9eabcea7-ad99-4fec-90ee-990515b2dc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare training data\n",
    "faces, labels = prepare_training_data(r'C:\\Users\\alesa\\OneDrive\\Desktop\\Dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85edc02f-a9d2-4884-8d64-aff2f38942c9",
   "metadata": {},
   "source": [
    "Train Face Recognizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a29a9ddb-048c-4cec-9e71-520f911935ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Face Recognizer\n",
    "face_recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "face_recognizer.train(faces, np.array(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64dc1404-aa60-478d-ab0e-3939502121f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict faces in test images\n",
    "def predict(test_img_paths):\n",
    "    results = []\n",
    "    \n",
    "    for test_img_path in test_img_paths:\n",
    "        img, gray, detected_faces = detect_faces(test_img_path)\n",
    "        \n",
    "        if len(detected_faces) == 0:\n",
    "            print(f\"No faces detected in image: {test_img_path}\")\n",
    "            results.append(img)  # Append original image if no face is detected\n",
    "            continue\n",
    "        \n",
    "        for (x, y, w, h) in detected_faces:\n",
    "            roi_gray = gray[y:y+w, x:x+h]\n",
    "            roi_gray = cv2.resize(roi_gray, (100, 100))  # Resize to match training image size\n",
    "            label, confidence = face_recognizer.predict(roi_gray)\n",
    "            name = label_to_name.get(label, \"Unknown\")\n",
    "            print(f\"Image: {test_img_path} - Predicted label: {label} ({name}) with confidence: {confidence}\")\n",
    "            cv2.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "            cv2.putText(img, name, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
    "        \n",
    "        # Collect result for each image\n",
    "        results.append(img)\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a561440-1017-4ec1-ba4c-959eec4940d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to concatenate images in a grid format\n",
    "def concatenate_images_in_grid(images, images_per_row=6):\n",
    "    if len(images) == 0:\n",
    "        return np.zeros((100, 100, 3), dtype=np.uint8)  # Return a blank image if no images\n",
    "\n",
    "    # Ensure all images have the same height\n",
    "    heights = [img.shape[0] for img in images]\n",
    "    max_height = max(heights)\n",
    "\n",
    "    # Resize all images to have the same height\n",
    "    resized_images = []\n",
    "    for img in images:\n",
    "        if img.shape[0] < max_height:\n",
    "            # Resize image to have the same height\n",
    "            new_width = int(img.shape[1] * (max_height / img.shape[0]))\n",
    "            resized_img = cv2.resize(img, (new_width, max_height))\n",
    "        else:\n",
    "            resized_img = img\n",
    "        resized_images.append(resized_img)\n",
    "\n",
    "    # Create rows of images with consistent width\n",
    "    rows = []\n",
    "    for i in range(0, len(resized_images), images_per_row):\n",
    "        row_images = resized_images[i:i+images_per_row]\n",
    "        max_width = max(img.shape[1] for img in row_images)\n",
    "        padded_row_images = [cv2.copyMakeBorder(img, 0, 0, 0, max_width - img.shape[1], cv2.BORDER_CONSTANT, value=[0, 0, 0]) for img in row_images]\n",
    "        row_image = np.hstack(padded_row_images)\n",
    "        rows.append(row_image)\n",
    "\n",
    "    # Pad rows to ensure same width for concatenation\n",
    "    max_row_width = max(row.shape[1] for row in rows)\n",
    "    padded_rows = [cv2.copyMakeBorder(row, 0, 0, 0, max_row_width - row.shape[1], cv2.BORDER_CONSTANT, value=[0, 0, 0]) for row in rows]\n",
    "\n",
    "    # Concatenate rows vertically\n",
    "    concatenated_image = np.vstack(padded_rows)\n",
    "    return concatenated_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e86a485-a0f2-4414-9215-b2324a4f85f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of test image paths\n",
    "test_img_paths = [\n",
    "r\"C:\\Users\\alesa\\OneDrive\\Desktop\\Dataset\\Abdullah_Gul\\Abdullah_Gul_0007.jpg\",\n",
    "r\"C:\\Users\\alesa\\OneDrive\\Desktop\\Dataset\\Abdullah_Gul\\Abdullah_Gul_0001.jpg\",\n",
    "r\"C:\\Users\\alesa\\OneDrive\\Desktop\\Dataset\\Abdullah_Gul\\Abdullah_Gul_0002.jpg\",\n",
    "r\"C:\\Users\\alesa\\OneDrive\\Desktop\\Dataset\\Abdullah_Gul\\Abdullah_Gul_0003.jpg\",\n",
    "r\"C:\\Users\\alesa\\OneDrive\\Desktop\\Dataset\\Abdullah_Gul\\Abdullah_Gul_0017.jpg\",\n",
    "r\"C:\\Users\\alesa\\OneDrive\\Desktop\\Dataset\\Abdullah_Gul\\Abdullah_Gul_0018.jpg\",\n",
    "r\"C:\\Users\\alesa\\OneDrive\\Desktop\\Dataset\\Abdullah_Gul\\Abdullah_Gul_0019.jpg\",\n",
    "   # Add more paths as needed\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf388763-c0d7-454b-8e4c-562296298aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: C:\\Users\\alesa\\OneDrive\\Desktop\\Dataset\\Abdullah_Gul\\Abdullah_Gul_0007.jpg - Predicted label: 18 (Abdullah_Gul) with confidence: 0.0\n",
      "Image: C:\\Users\\alesa\\OneDrive\\Desktop\\Dataset\\Abdullah_Gul\\Abdullah_Gul_0001.jpg - Predicted label: 18 (Abdullah_Gul) with confidence: 0.0\n",
      "Image: C:\\Users\\alesa\\OneDrive\\Desktop\\Dataset\\Abdullah_Gul\\Abdullah_Gul_0002.jpg - Predicted label: 18 (Abdullah_Gul) with confidence: 0.0\n",
      "Image: C:\\Users\\alesa\\OneDrive\\Desktop\\Dataset\\Abdullah_Gul\\Abdullah_Gul_0003.jpg - Predicted label: 18 (Abdullah_Gul) with confidence: 0.0\n",
      "Image: C:\\Users\\alesa\\OneDrive\\Desktop\\Dataset\\Abdullah_Gul\\Abdullah_Gul_0017.jpg - Predicted label: 18 (Abdullah_Gul) with confidence: 0.0\n",
      "Image: C:\\Users\\alesa\\OneDrive\\Desktop\\Dataset\\Abdullah_Gul\\Abdullah_Gul_0018.jpg - Predicted label: 18 (Abdullah_Gul) with confidence: 0.0\n",
      "Image: C:\\Users\\alesa\\OneDrive\\Desktop\\Dataset\\Abdullah_Gul\\Abdullah_Gul_0019.jpg - Predicted label: 18 (Abdullah_Gul) with confidence: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Predict faces in all test images\n",
    "predicted_imgs = predict(test_img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ffd805d-f1f0-4ac2-ad5a-e1245898429e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate images in a grid format\n",
    "concatenated_img = concatenate_images_in_grid(predicted_imgs, images_per_row=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9512b04-31fe-44cd-9a27-d8b32252e121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display concatenated image\n",
    "cv2.imshow('Concatenated Images', concatenated_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0e380c-1b76-4642-9e63-48ed5a615a83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
